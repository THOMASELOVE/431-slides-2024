---
title: "431 Class 16"
author: Thomas E. Love, Ph.D.
date: "2024-10-17"
format:
  revealjs: 
    theme: default
    self-contained: true
    slide-number: true
    footnotes-hover: true
    preview-links: auto
    logo: 431_2024_logo.png
    footer: "431 Class 16 | 2024-10-17 | <https://thomaselove.github.io/431-2024/>"
---

## Today's Agenda

- Discussion of Quiz 1
- Dealing with Missing Data
- Simple (Single) Imputation using the `mice` package
- Multiple Imputation using the `mice` package

(MICE = Multiple Imputation through Chained Equations)

- Breakout Activity 3 Results

## Today's Packages

```{r}
#| echo: true
#| message: false

library(janitor)
library(googlesheets4)
library(knitr)
library(kableExtra)
library(mice)
library(naniar)
library(xfun)
library(easystats)
library(tidyverse)

theme_set(theme_light())

source("c16/data/Love-431.R")
```

## 700 Veterans with HBP {.smaller}

700 male veterans with a hypertension diagnosis.

- Pulse Pressure = Systolic BP - Diastolic BP.

```{r}
#| echo: true

hbp700 <- read_csv("c16/data/hbp700.csv", show_col_types = FALSE) |>
  janitor::clean_names() |>
  mutate(across(where(is.character), as_factor)) |>
  mutate(pp = sbp - dbp) |>
  mutate(subject = as.character(subject)) 

dim(hbp700)
hbp700 |> head(4)
```

## Missingness in `hbp700` {.smaller}

```{r}
#| echo: true
miss_var_summary(hbp700)
miss_case_table(hbp700)
```

## Categorical Variables in `hbp700`

```{r}
#| echo: true

hbp700 |> tabyl(race, tobacco) |> 
  adorn_totals(where = c("row", "col"))

hbp700 |> tabyl(race) |> adorn_pct_formatting()

hbp700 |> tabyl(tobacco) |> adorn_pct_formatting()
```




## Quantitative Variables in `hbp700`

```{r}
#| echo: true

s_1 <- hbp700 |> reframe(lovedist(age)) |> mutate(var = "age")
s_2 <- hbp700 |> reframe(lovedist(nincome)) |> mutate(var = "nincome")
s_3 <- hbp700 |> reframe(lovedist(bmi)) |> mutate(var = "bmi")
s_4 <- hbp700 |> reframe(lovedist(ldl)) |> mutate(var = "ldl")
s_5 <- hbp700 |> reframe(lovedist(sbp)) |> mutate(var = "sbp")
s_6 <- hbp700 |> reframe(lovedist(dbp)) |> mutate(var = "dbp")
s_7 <- hbp700 |> reframe(lovedist(pp)) |> mutate(var = "pp")

rbind(s_1, s_2, s_3, s_4, s_5, s_6, s_7) |> 
  relocate(var) |> kable(digits = 1) |>
  kable_styling(full_width = F, font_size = 20)

```

## Today's Outcome: Pulse Pressure

- Pulse Pressure = Systolic BP - Diastolic BP.

```{r}
#| echo: true
#| fig-height: 3
hbp700 <- hbp700 |> mutate(pp = sbp - dbp)

ggplot(hbp700, aes(x = pp, y = "pp")) + geom_violin() + 
  geom_boxplot(width = 0.3) + labs(x = "Pulse Pressure (SBP - DBP)", y = "") +
  stat_summary(fun = "mean", geom = "point", col = "red", size = 2)
```


## Using `race` to predict `sbp` - `dbp`

- 700 subjects: 1 missing `sbp` & `dbp` plus 112 missing `race`.

```{r}
#| echo: true

fit1 <- lm((sbp-dbp) ~ race, data = hbp700)
summary(fit1)
```

## Assessing `fit1`

```{r}
#| echo: true
n_obs(fit1)

model_parameters(fit1)

model_performance(fit1)
```

## Add in age, as a covariate

```{r}
#| echo: true

fit2 <- lm((sbp-dbp) ~ race + age, data = hbp700)
summary(fit2)
```

## Assessing `fit2`

```{r}
#| echo: true
n_obs(fit2) # any more missingness?

model_parameters(fit2)

model_performance(fit2)
```

# Multiple Imputation: Potential and Pitfalls

## Sterne et al. 2009 *BMJ*  {.smaller}

Multiple imputation for missing data in epidemiological and clinical research: potential and pitfalls

> In this article, we review the reasons why missing data may lead to bias and loss of information in epidemiological and clinical research. We discuss the circumstances in which multiple imputation may help by reducing bias or increasing precision, as well as describing potential pitfalls in its application. Finally, we describe the recent use and reporting of analyses using multiple imputation in general medical journals, and suggest guidelines for the conduct and reporting of such analyses.

- https://www.bmj.com/content/338/bmj.b2393

**Note**: The next 7 slides are derived from Sterne et al.

## An Example from Sterne et al. {.smaller}

Consider, for example, a study investigating the association of systolic blood pressure with the risk of subsequent coronary heart disease, in which data on systolic blood pressure are missing for some people. 

The probability that systolic blood pressure is missing is likely to:

- decrease with age (doctors are more likely to measure it in older people), 
- decrease with increasing body mass index, and 
- decrease with history of smoking (doctors are more likely to measure it in people with heart disease risk factors or comorbidities). 

If we assume that data are missing at random and that we have systolic blood pressure data on a representative sample of individuals within strata of age, smoking, body mass index, and coronary heart disease, then we can use multiple imputation to estimate the overall association between systolic blood pressure and coronary heart disease.

## Missing Data Mechanisms {.smaller}

- **Missing completely at random** There are no systematic differences between the missing values and the observed values. 
    - For example, blood pressure measurements may be missing because of breakdown of an automatic sphygmomanometer.
- **Missing at random** Any systematic difference between the missing and observed values can be explained by other observed data. 
    - For example, missing BP measurements may be lower than measured BPs but only because younger people more often have a missing BP.
- **Missing not at random** Even after the observed data are taken into account, systematic differences remain between the missing values and the observed values. 
    - For example, people with high BP may be more likely to have headaches that cause them to miss clinic appointments.

"Missing at random" is an **assumption** that justifies the analysis, and is not a property of the data.

## Trouble: Data missing not at random {.smaller}

Sometimes, it is impossible to account for systematic differences between missing and observed values using the available data.

- In such (MNAR) cases, multiple imputation may give misleading results. 
    - Those results can be either more or less misleading than a complete case analysis. 
- For example, consider a study investigating predictors of depression. 
    - If individuals are more likely to miss appointments because they are depressed on the day of the appointment, then it may be impossible to make the MAR assumption plausible, even if a large number of variables is included in the imputation model.

Where complete cases and multiple imputation analyses give different results, the analyst should attempt to understand why, and this should be reported in publications.

## What if the data are MCAR? {.smaller}

If we assume data are MAR, then unbiased and statistically more powerful analyses (compared with analyses based on complete cases) can generally be done by including individuals with incomplete data.

There are circumstances in which analyses of **complete cases** will not lead to bias.

- Missing data in predictor variables do not cause bias in analyses of complete cases if the reasons for the missing data are unrelated to the outcome. 
    - In such cases, imputing missing data may lessen the loss of precision and power resulting from exclusion of individuals with incomplete predictor variables but are not required in order to avoid bias.

## Stages of Multiple Imputation (1 of 2) {.smaller}

> Multiple imputation ... aims to allow for the uncertainty about the missing data by creating several different plausible imputed data sets and appropriately combining results obtained from each of them.

The first stage is to create multiple copies of the dataset, with the missing values replaced by imputed values. 

- The imputation procedure must fully account for all uncertainty in predicting the missing values by injecting appropriate variability into the multiple imputed values; we can never know the true values of the missing data.

Note that single Imputation of missing values usually causes standard errors to be too small, since it fails to account for the fact that we are uncertain about the missing values.


## Stages of Multiple Imputation (2 of 2) {.smaller}

The second stage is to use standard statistical methods to fit the model of interest to each of the imputed datasets. 

- Estimated associations in each of the imputed datasets will differ because of the variation introduced in the imputation of the missing values, and they are only useful when averaged together to give overall estimated associations. 
- Standard errors are calculated using Rubin's rules, which take account of the variability in results between the imputed datasets, reflecting the uncertainty associated with the missing values.
- Valid inferences are obtained because we are averaging over the distribution of the missing data given the observed data.

## Back to our little example

```{r}
#| echo: true
fit1 <- lm(pp ~ race, data = hbp700)
fit2 <- lm(pp ~ race + age, data = hbp700)
```

How many subjects have complete / missing data affecting our models?

```{r}
#| echo: true

hbp_sub <- hbp700 |> select(subject, sbp, dbp, pp, race, age)

hbp_sub |> pct_complete_case()
hbp_sub |> pct_miss_case()
```

So how many imputations should we create?

## Building 20 imputations with `mice`

```{r}
#| echo: true

set.seed(20241017)

hbp_mice20 <- mice(hbp_sub, m = 20, printFlag = FALSE)
```

Summary on next slide...

## Summarize Imputation Process {.smaller}

```{r}
#| echo: true
summary(hbp_mice20)
```

See Heymans and Eekhout sections 4.6 - 4.14 for more information.

## Imputation Options within `mice` {.smaller}

Default methods include:

- `pmm` predictive mean matching (default choice for quantitative variables)
- `logreg` logistic regression (default for binary categorical variables)
- `polyreg` polytomous logistic regression (for nominal multi-categorical variables)
- `polr` proportional odds logistic regression (for ordinal categories)

but there are `cart` methods and many others available, too.

## What should we include in an imputation model? {.smaller}

1. If things you are imputing are not Normally distributed, this can pose special challenges, and either a transformation or choosing an imputation method which is robust to these concerns is helpful.
2. Include the outcome when imputing predictors. It causes you to conclude the relationship is weaker than it actually is, if you don't.
3. The MAR assumption may only be reasonable when a certain variable is included in the model.
    - As a result, it's usually a good idea to include as wide a range of variables in imputation models as possible. The concerns we'd have about parsimony in outcome models don't apply here.


## Store one (or more) of the imputed data sets

This will store the fifth imputed data set in `imp_5`.

```{r}
#| echo: true
imp_5 <- complete(hbp_mice20, 5) |> tibble()

dim(imp_5)
n_miss(imp_5)
```

## Fit `fit2` on 5th imputation

```{r}
#| echo: true

fit2_i5 <- lm((sbp-dbp) ~ race + age, data = imp_5)
summary(fit2_i5)
```

## Assessing `fit2_i5`

```{r}
#| echo: true
n_obs(fit2_i5) # any missingness?

model_parameters(fit2_i5)

model_performance(fit2_i5)
```

## Check model after single imputation

```{r}
#| echo: true

check_model(fit2_i5)
```


## `fit2` on each imputed data frame

3 estimates (coefficients) times 20 imputed data sets = 60 rows.

```{r}
#| echo: true
m2_mods <- with(hbp_mice20, lm(pp ~ race + age))

summary(m2_mods)
```

## Pool across the 20 imputations

```{r}
#| echo: true
m2_pool <- pool(m2_mods)

n_obs(m2_pool)

model_parameters(m2_pool)
```

## Compare to our original `fit2`

```{r}
#| echo: true
n_obs(fit2)

model_parameters(fit2)
```

## Estimate $R^2$ and Adjusted $R^2$

```{r}
#| echo: true

pool.r.squared(m2_mods)

pool.r.squared(m2_mods, adjusted = TRUE)

model_performance(fit2) # original model with NAs
```

Much, much more to come. See [Chapter 17 of our Course Book](https://thomaselove.github.io/431-book/17_adjtrans.html) for more discussion and an additional example.

# Breakout Activity 3

## R Packages

```{r}
#| echo: true
#| message: false

library(janitor)
library(googlesheets4)
library(naniar)
library(xfun)
library(easystats)
library(tidyverse)

theme_set(theme_light())

source("c16/data/Love-431.R")
```

## Ingest the `movies_2024-10-15` data

```{r}
#| echo: true
gs4_deauth()

url <- "https://docs.google.com/spreadsheets/d/16fm1693sFjau9sIM-ORamxLL3ZMrBeRSxXqWpP8IBDs/edit?gid=0#gid=0"

mov_raw <- read_sheet(url, na = c("", "NA"))

mov_clean <- mov_raw |> 
  janitor::clean_names() |>
  mutate(across(where(is.character), as_factor)) |>
  mutate(across(c(mov_id, movie, director, star_1, star_2, star_3, origin,
                  fc_link, rt_link, imdb_cats, synopsis, imdb_id, imdb_link),
                as.character))
```

# Tukey (from Ajay)

## Data Clean for Tukey (from Ajay)

Outcome | Binary  | Covariate | Multi-Cat
:-----------------------: | :-----------------------: | :-----------------------: | :-----------------------: 
potentially triggering events | primary language English | length | streaming services 


```{r}
#| echo: true

mov_t1 <- mov_clean |>
  select(mov_id, movie, triggers, lang_1, length, stream_n) |>
  mutate(lang_english = ifelse(lang_1 == "English", 1, 0),
         length_s = scale(length, center = TRUE, scale = TRUE),
         stream_n = as_factor(stream_n),
         stream_f = fct_collapse(stream_n, 
                                 "0-2" = c(0, 1, 2), "4-5" = c(4, 5)),
         stream_f = fct_relevel(stream_f, "0-2", "3", "4-5"))
```

## Missing Status

Tukey (from Ajay)

```{r}
#| echo: true

miss_case_table(mov_t1)
miss_var_summary(mov_t1) |> filter(n_miss > 0)
```

## Outcome and Covariate 

Tukey (from Ajay)

```{r}
#| echo: true

a1 <- mov_t1 |> reframe(lovedist(triggers)) |> mutate(var = "triggers")
a2 <- mov_t1 |> reframe(lovedist(length)) |> mutate(var = "length")
a3 <- mov_t1 |> reframe(lovedist(length_s)) |> mutate(var = "length_s")

rbind(a1, a2, a3) |> relocate(var) |> 
  kable(digits = 1) |> kable_styling(font_size = 20)
```

## Correlations

Tukey (from Ajay)

```{r}
#| echo: true

correlation(mov_t1 |> select(triggers, length_s, length))
```

## Binary and Multi-Category Variables

Tukey (from Ajay)

```{r}
#| echo: true

mov_t1 |> tabyl(lang_english, stream_n) |>
  adorn_totals(where = c("row", "col"))

mov_t1 |> tabyl(lang_english, stream_f) |>
  adorn_totals(where = c("row", "col"))
```

## Fit 1

Tukey (from Ajay)

```{r}
#| echo: true

fit1_t1 <- lm(triggers ~ lang_english, data = mov_t1)

n_obs(fit1_t1)

model_parameters(fit1_t1)

model_performance(fit1_t1)
```

## Fit 2

Tukey (from Ajay)

```{r}
#| echo: true

fit2_t1 <- lm(triggers ~ lang_english + length_s, data = mov_t1)

n_obs(fit2_t1)

model_parameters(fit2_t1)

model_performance(fit2_t1)
```

## Fit 3

Tukey (from Ajay)

```{r}
#| echo: true

fit3_t1 <- lm(triggers ~ stream_f + length_s, data = mov_t1)

n_obs(fit3_t1)

model_parameters(fit3_t1)

model_performance(fit3_t1)
```

# Hard R Cafe

## Data Clean for Hard R Cafe

Outcome | Binary  | Covariate | Multi-Cat
:-----------------------: | :-----------------------: | :-----------------------: | :-----------------------: 
potentially triggering events | country of origin includes US | year (or age) | oscars won


```{r}
#| echo: true

mov_hrc <- mov_clean |>
  select(mov_id, movie, triggers, origin, year, oscars) |>
  mutate(origin_us = as.numeric(str_detect(origin, pattern = "USA")),
         age = 2024 - year,
         age_s = scale(age, center = TRUE, scale = TRUE),
         oscars = as_factor(oscars),
         oscar_f = fct_lump(oscars, n = 2, other_level = "2+"))
```

## Missing Status

Hard R Cafe

```{r}
#| echo: true

miss_case_table(mov_hrc)
miss_var_summary(mov_hrc) |> filter(n_miss > 0)
```

## Outcome and Covariate 

Hard R Cafe

```{r}
#| echo: true

a1 <- mov_hrc |> reframe(lovedist(triggers)) |> mutate(var = "triggers")
a2 <- mov_hrc |> reframe(lovedist(age)) |> mutate(var = "age")
a3 <- mov_hrc |> reframe(lovedist(age_s)) |> mutate(var = "age_s")

rbind(a1, a2, a3) |> relocate(var) |> 
  kable(digits = 1) |> kable_styling(font_size = 20)
```

## Correlations

Hard R Cafe

```{r}
#| echo: true

correlation(mov_hrc |> select(triggers, age_s, age))
```

## Binary and Multi-Category Variables

Hard R Cafe

```{r}
#| echo: true

mov_hrc |> tabyl(origin_us, oscars) |>
  adorn_totals(where = c("row", "col"))

mov_hrc |> tabyl(origin_us, oscar_f) |>
  adorn_totals(where = c("row", "col"))
```

## Fit 1

Hard R Cafe

```{r}
#| echo: true

fit1_hrc <- lm(triggers ~ origin_us, data = mov_hrc)

n_obs(fit1_hrc)

model_parameters(fit1_hrc)

model_performance(fit1_t1)
```

## Fit 2

Hard R Cafe

```{r}
#| echo: true

fit2_hrc <- lm(triggers ~ origin_us + age_s, data = mov_hrc)

n_obs(fit2_hrc)

model_parameters(fit2_hrc)

model_performance(fit2_hrc)
```

## Fit 3

Hard R Cafe

```{r}
#| echo: true

fit3_hrc <- lm(triggers ~ oscar_f + age_s, data = mov_hrc)

n_obs(fit3_hrc)

model_parameters(fit3_hrc)

model_performance(fit3_hrc)
```

# Tukey (from Atticus)

## Data Clean: Tukey (from Atticus)

Outcome | Binary  | Covariate | Multi-Cat
:-----------------------: | :-----------------------: | :-----------------------: | :-----------------------: 
potentially triggering events | star 1 gender | length | oscars won

```{r}
#| echo: true

mov_t2 <- mov_clean |>
  select(mov_id, movie, triggers, gen_1, length, oscars) |>
  mutate(length_s = scale(length, center = TRUE, scale = TRUE),
         oscars = as_factor(oscars),
         oscar_f = fct_lump(oscars, n = 2, other_level = "2+"))
```

## Missing Status

Tukey (from Atticus)

```{r}
#| echo: true

miss_case_table(mov_t2)
miss_var_summary(mov_t2) |> filter(n_miss > 0)
```

## Outcome and Covariate 

Tukey (from Atticus)

```{r}
#| echo: true

a1 <- mov_t2 |> reframe(lovedist(triggers)) |> mutate(var = "triggers")
a2 <- mov_t2 |> reframe(lovedist(length)) |> mutate(var = "length")
a3 <- mov_t2 |> reframe(lovedist(length_s)) |> mutate(var = "length_s")

rbind(a1, a2, a3) |> relocate(var) |> 
  kable(digits = 1) |> kable_styling(font_size = 20)
```

## Correlations

Tukey (from Atticus)

```{r}
#| echo: true

correlation(mov_t2 |> select(triggers, length_s, length))
```

## Binary and Multi-Category Variables

Tukey (from Atticus)

```{r}
#| echo: true

mov_t2 |> tabyl(gen_1, oscars) |>
  adorn_totals(where = c("row", "col"))

mov_t2 |> tabyl(gen_1, oscar_f) |>
  adorn_totals(where = c("row", "col"))
```

## Fit 1

Tukey (from Atticus)

```{r}
#| echo: true

fit1_t2 <- lm(triggers ~ gen_1, data = mov_t2)

n_obs(fit1_t2)

model_parameters(fit1_t2)

model_performance(fit1_t2)
```

## Fit 2

Tukey (from Atticus)

```{r}
#| echo: true

fit2_t2 <- lm(triggers ~ gen_1 + length_s, data = mov_t2)

n_obs(fit2_t2)

model_parameters(fit2_t2)

model_performance(fit2_t2)
```

## Fit 3

Tukey (from Atticus)

```{r}
#| echo: true

fit3_t2 <- lm(triggers ~ oscar_f + length_s, data = mov_t2)

n_obs(fit3_t2)

model_parameters(fit3_t2)

model_performance(fit3_t2)
```

# Halloween Time Stats

## Data Clean for Halloween Time Stats

Outcome | Binary  | Covariate | Multi-Cat
:-----------------------: | :-----------------------: | :-----------------------: | :-----------------------: 
budget | origin in US | year (or age) | Bechdel-Wallace

```{r}
#| echo: true

mov_hts <- mov_clean |>
  select(mov_id, movie, budget, origin, year, bw_rating) |>
  mutate(budgetM = budget/1000000,
         origin_us = as.numeric(str_detect(origin, pattern = "USA")),
         age = 2024 - year,
         age_s = scale(age, center = TRUE, scale = TRUE))
```

## Missing Status

Halloween Time Stats

```{r}
#| echo: true

miss_case_table(mov_hts)
miss_var_summary(mov_hts) |> filter(n_miss > 0)
```

## Outcome and Covariate 

Halloween Time Stats

```{r}
#| echo: true

a1 <- mov_hts |> reframe(lovedist(budgetM)) |> mutate(var = "budgetM")
a2 <- mov_hts |> reframe(lovedist(age)) |> mutate(var = "age")
a3 <- mov_hts |> reframe(lovedist(age_s)) |> mutate(var = "age_s")

rbind(a1, a2, a3) |> relocate(var) |> 
  kable(digits = 1) |> kable_styling(font_size = 20)
```

## Correlations

Halloween Time Stats

```{r}
#| echo: true

correlation(mov_hts |> select(budgetM, age_s, age))
```

## Binary and Multi-Category Variables

Halloween Time Stats

```{r}
#| echo: true

mov_hts |> tabyl(origin_us, bw_rating) |>
  adorn_totals(where = c("row", "col"))
```

## Fit 1

Halloween Time Stats

```{r}
#| echo: true

fit1_hts <- lm(budgetM ~ origin_us, data = mov_hts)

n_obs(fit1_hts)

model_parameters(fit1_hts)

model_performance(fit1_hts)
```

## Fit 2

Halloween Time Stats

```{r}
#| echo: true

fit2_hts <- lm(budgetM ~ origin_us + age_s, data = mov_hts)

n_obs(fit2_hts)

model_parameters(fit2_hts)

model_performance(fit2_hts)
```

## Fit 3

Halloween Time Stats

```{r}
#| echo: true

fit3_hts <- lm(budgetM ~ bw_rating + age_s, data = mov_hts)

n_obs(fit3_hts)

model_parameters(fit3_hts)

model_performance(fit3_hts)
```


# Data Cleaning and Missing Status only

## Data Clean for Something Unique Tokyo Drift

Outcome | Binary  | Covariate | Multi-Cat
:-----------------------: | :-----------------------: | :-----------------------: | :-----------------------: 
budget | origin in US | length | oscars won

```{r}
#| echo: true

mov_sutd <- mov_clean |>
  select(mov_id, movie, budget, origin, length, oscars) |>
  mutate(budgetM = budget/1000000,
         origin_us = as.numeric(str_detect(origin, pattern = "USA")),
         length_s = scale(length, center = TRUE, scale = TRUE),
         oscars = as_factor(oscars),
         oscar_f = fct_lump(oscars, n = 2, other_level = "2+"))
```

## Missing Status

Something Unique Tokyo Drift

```{r}
#| echo: true

miss_case_table(mov_sutd)
miss_var_summary(mov_sutd) |> filter(n_miss > 0)
```

## Data Clean for PB&J

Outcome | Binary  | Covariate | Multi-Cat
:-----------------------: | :-----------------------: | :-----------------------: | :-----------------------: 
gross revenue | star 1 gender | budget | oscars won

```{r}
#| echo: true

mov_pbj <- mov_clean |>
  select(mov_id, movie, gross_world, gen_1, budget, oscars) |>
  mutate(grossM = gross_world/1000000,
         budget_s = scale(budget, center = TRUE, scale = TRUE),
         oscars = as_factor(oscars),
         oscar_f = fct_lump(oscars, n = 2, other_level = "2+"))
```

## Missing Status

PB&J

```{r}
#| echo: true

miss_case_table(mov_pbj)
miss_var_summary(mov_pbj) |> filter(n_miss > 0)
```

## Data Clean for And Then There Were Three

Outcome | Binary  | Covariate | Multi-Cat
:-----------------------: | :-----------------------: | :-----------------------: | :-----------------------: 
gross revenue | drama | sex-nudity rating | ebert rating

```{r}
#| echo: true

mov_attwt <- mov_clean |>
  select(mov_id, movie, gross_world, drama, kim_sn, ebert) |>
  mutate(grossM = gross_world/1000000,
         ebert = as_factor(ebert),
         ebert_f = fct_lump(ebert, n = 4, other_level = "1-2"),
         ebert_f = fct_relevel(ebert_f, "1-2"))
```

## Missing Status

And Then There Were Three

```{r}
#| echo: true

miss_case_table(mov_attwt)
miss_var_summary(mov_attwt) |> filter(n_miss > 0)
```


## Data Clean for Vintage Macbooks

Outcome | Binary  | Covariate | Multi-Cat
:-----------------------: | :-----------------------: | :-----------------------: | :-----------------------: 
awards won | has Dr. Love seen | length | Bechdel-Wallace

```{r}
#| echo: true

mov_vm <- mov_clean |>
  select(mov_id, movie, awards, dr_love, length, bw_rating) |>
  mutate(length_s = scale(length, center = TRUE, scale = TRUE))
```

## Missing Status

Vintage Macbooks

```{r}
#| echo: true

miss_case_table(mov_vm)
miss_var_summary(mov_vm) |> filter(n_miss > 0)
```


## Data Clean for Ghostbusters

Outcome | Binary  | Covariate | Multi-Cat
:-----------------------: | :-----------------------: | :-----------------------: | :-----------------------: 
awards won | star 1 gender | year (or age) | Bechdel-Wallace

```{r}
#| echo: true

mov_gb <- mov_clean |>
  select(mov_id, movie, awards, gen_1, year, bw_rating) |>
  mutate(age = 2024 - year,
         age_s = scale(age, center = TRUE, scale = TRUE))
```

## Missing Status

Ghostbusters

```{r}
#| echo: true

miss_case_table(mov_gb)
miss_var_summary(mov_gb) |> filter(n_miss > 0)
```


## Session Information

```{r}
#| echo: true
session_info()
```